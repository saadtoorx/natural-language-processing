# Sentiment Analyzer AI

A production-ready sentiment analysis application powered by a local Mistral model via Ollama. Features a FastAPI backend and a modern Streamlit frontend.

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.127+-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.49+-red.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## âœ¨ Features

- ğŸ­ **Sentiment Analysis** - Analyze sentiment of any text with AI
- ğŸ“Š **Batch Processing** - Analyze multiple texts or upload CSV files
- ğŸ“‹ **History** - Track and view your past analyses
- ğŸ“¥ **Export Results** - Download results as CSV or JSON
- âš™ï¸ **Configurable** - Adjust model parameters (temperature, model name)
- ğŸ” **Health Status** - Real-time API and model status monitoring
- ğŸŸ¢ **Visual Feedback** - Color-coded sentiment indicators
- ğŸ”’ **Privacy** - All processing happens locally

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     HTTP      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     HTTP      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚   POST/GET    â”‚                 â”‚   /api        â”‚                 â”‚
â”‚   Streamlit     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚    FastAPI      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚     Ollama      â”‚
â”‚   Frontend      â”‚               â”‚    Backend      â”‚               â”‚    (Mistral)    â”‚
â”‚   (Port 8501)   â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚   (Port 8000)   â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚   (Port 11434)  â”‚
â”‚                 â”‚     JSON      â”‚                 â”‚     JSON      â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- **Python 3.10+** - [Download](https://www.python.org/downloads/)
- **Ollama** - [Install Ollama](https://ollama.ai/download)
- **Mistral Model** - Run `ollama pull mistral` after installing Ollama

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone <repository-url>
cd "Project 2 Sentiment Analyzer AI Project"
```

### 2. Create Virtual Environment

```bash
python -m venv venv

# Windows
.\venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment (Optional)

```bash
cp .env.example .env
# Edit .env with your settings
```

### 5. Start Ollama

Make sure Ollama is running:
```bash
ollama serve
```

### 6. Run the Application

**Terminal 1 - Start Backend:**
```bash
uvicorn backend.main:app --reload
```

**Terminal 2 - Start Frontend:**
```bash
streamlit run frontend/app.py
```

### 7. Open the App

Navigate to `http://localhost:8501` in your browser.

## ğŸ“š API Documentation

Once the backend is running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Check API and Ollama status |
| POST | `/analyze/` | Analyze single text (Form) |
| POST | `/analyze/json` | Analyze single text (JSON) |
| POST | `/analyze/batch` | Analyze multiple texts |

## ğŸ¨ Screenshots

*Coming soon*

## ğŸ› ï¸ Configuration

Environment variables (set in `.env`):

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_URL` | `http://localhost:11434` | Ollama API URL |
| `DEFAULT_MODEL` | `mistral` | Model to use by default |

## ğŸ“ Project Structure

```
Sentiment Analyzer AI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py          # FastAPI application
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py           # Streamlit application
â”œâ”€â”€ .env.example         # Environment template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) - Local LLM runner
- [Mistral AI](https://mistral.ai/) - Mistral model
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [Streamlit](https://streamlit.io/) - Data app framework
